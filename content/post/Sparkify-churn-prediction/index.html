---
title: Customer Churn Prediction for Sparkify using PySpark
author: ~
date: '2020-11-09'
slug: Sparkify-churn-prediction
categories: []
tags:
- Machine learning
- Feature engineering
- Spark
subtitle: ''
summary: Use Apache Spark for large-scale data processing to predict customer churn
authors: [Wei Guo]
lastmod: []
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div class="figure">
<img src="customer_churn.png" style="width:100.0%" />

</div>
<p>Predicting customer churn is a challenging and common problem for any e-commerce business in which everything depends on the behavior of customers. Customer churn is often defined as the process in which the customers downgrade from premium to free tier or stop using the products or services of a business. Thus, the ability to predict which users are at risk of churning, while there is still time to offer them discounts or other incentives, will greatly help to prevent every custormer-facing business from suffering severe financial losses.</p>
<div id="overview" class="section level2">
<h2>Overview</h2>
<ul>
<li><strong><a href="#data-preparation">Data preparation</a></strong>
<ul>
<li><a href="#data-description">Data description</a></li>
<li><a href="#data-cleaning">Data cleaning</a></li>
</ul></li>
<li><strong><a href="#feature-engineering-and-exploratory-data-analysis">Feature engineering and exploratory data analysis</a></strong>
<ul>
<li><a href="#feature-correlation">Feature correlation</a></li>
<li><a href="#feature-transformation">Feature transformation</a></li>
</ul></li>
<li><strong><a href="#modeling-and-evaluation">Modeling and evaluation</a></strong>
<ul>
<li><a href="#performance-metrics">Performance metrics</a></li>
<li><a href="#model-selection">Model selection</a></li>
<li><a href="#hyperparameter-tuning">Hyperparameter tuning</a></li>
<li><a href="#feature-importance">Feature importance</a></li>
</ul></li>
<li><strong><a href="#conclusion">Conclusion</a></strong></li>
</ul>
<p>The data set in this project is provided by Sparkify, a fictitious digital music service created by Udacity, to resemble the data sets generated by companies such as Spotify or Pandora. Millions of users stream their favorite songs through Sparkify’s platform on a daily basis, either using the free tier that places advertisements between the songs or using the premiumn subscription model which is typically ad-free by paying a monthly flat rate. Users can upgrade, downgrade or cancel their service at any time. Thus, it is crucial to ensure the users love the service. Our goal in this project is to help Spakify identify potential churn users by building and training a binary classifier so as to save the business millions in revenue.</p>
</div>
<div id="data-preparation" class="section level2">
<h2>Data preparation</h2>
<p>Data is generated everytime a user interacts with the service while playing songs, logging out, liking a song with a thumbs up or adding a friend etc. The full dataset collects approximately 26 million records from 22277 users, whereas a smaller subset contains 286500 records from 225 users between October 1, 2018 and December 3, 2018. The model development proces present here is performed on the smaller subset using Python API for Spark, PySpark.</p>
<div id="data-description" class="section level3">
<h3>Data description</h3>
<p>Since there is no documentation provided alongside the datasets, we first have to conduct data exploration to gain a sense of the data. A detailed description of the variables is summarized below.</p>
<center>
<div style="width:100%;">
<table style="width:83%;">
<colgroup>
<col width="13%" />
<col width="13%" />
<col width="55%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Data Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>artist</strong></td>
<td>string</td>
<td>artist name</td>
</tr>
<tr class="even">
<td><strong>auth</strong></td>
<td>categorical</td>
<td>authentication level (Logged In, Logged Out, Cancelled, Guest)</td>
</tr>
<tr class="odd">
<td><strong>firstName</strong></td>
<td>string</td>
<td>user’s first name</td>
</tr>
<tr class="even">
<td><strong>gender</strong></td>
<td>categorical</td>
<td>user’s gender (M and F)</td>
</tr>
<tr class="odd">
<td><strong>itemInSession</strong></td>
<td>int</td>
<td>log count in a given session</td>
</tr>
<tr class="even">
<td><strong>lastName</strong></td>
<td>string</td>
<td>user’s last name</td>
</tr>
<tr class="odd">
<td><strong>length</strong></td>
<td>double</td>
<td>song’s length in seconds</td>
</tr>
<tr class="even">
<td><strong>level</strong></td>
<td>string</td>
<td>subscription level (free and paid)</td>
</tr>
<tr class="odd">
<td><strong>location</strong></td>
<td>string</td>
<td>user’s location</td>
</tr>
<tr class="even">
<td><strong>method</strong></td>
<td>categorical</td>
<td>http request method (GET and PUT)</td>
</tr>
<tr class="odd">
<td><strong>page</strong></td>
<td>categorical</td>
<td>type of interaction (NextSong, Home, Cancellation Confirmation, etc.)</td>
</tr>
<tr class="even">
<td><strong>registration</strong></td>
<td>int</td>
<td>user’s registration timestamp</td>
</tr>
<tr class="odd">
<td><strong>sessionId</strong></td>
<td>int</td>
<td>session to which the log belongs to</td>
</tr>
<tr class="even">
<td><strong>song</strong></td>
<td>string</td>
<td>song name currently being played</td>
</tr>
<tr class="odd">
<td><strong>status</strong></td>
<td>categorical</td>
<td>http status code (200, 307 and 404)</td>
</tr>
<tr class="even">
<td><strong>ts</strong></td>
<td>int</td>
<td>timestamp of a given log</td>
</tr>
<tr class="odd">
<td><strong>userAgent</strong></td>
<td>string</td>
<td>agent used by the user to access the streaming service</td>
</tr>
<tr class="even">
<td><strong>userId</strong></td>
<td>string</td>
<td>user identifier</td>
</tr>
</tbody>
</table>
</div>
</center>
</div>
<div id="data-cleaning" class="section level3">
<h3>Data cleaning</h3>
<p>After checking null values, we notice variables with null values can be divided into two groups, i.e.:</p>
<ul>
<li>Group 1 (user-related): <strong>firstName</strong>, <strong>gender</strong>, <strong>lastName</strong>, <strong>location</strong>, <strong>registration</strong> and <strong>userAgent</strong></li>
<li>Group 2 (song-related): <strong>artist</strong>, <strong>length</strong> and <strong>song</strong></li>
</ul>
<p>It seems variables in each group are tied in a certain way with nulls. With more data wrangling, we find:</p>
<ul>
<li>When <strong>auth</strong> is <em>LoggedOut</em>, variable values in both groups are nulls and values in <strong>userId</strong> are empty strings.</li>
<li>All the rows with missing values in the <strong>userId</strong> column and all other user-related columns correspond to <em>Logged Out</em> or <em>Guest</em> authentication levels.</li>
<li>Variable values in Group 2 are nulls whenever <strong>page</strong> is not <em>NextSong</em>, which makes sense since these variables are song-related.</li>
</ul>
<p>Based on our observations above, we only need to remove the records when the <strong>userId</strong> is an empty string. Additionally, we replace the <strong>location</strong> column by the corresponding state name to simplify the location-related analysis. If the location links to multiple states, we select the first state to represent the user’s location.</p>
<pre class="python"><code>def clean_data(df):
    &quot;&quot;&quot;Clean a Sparkify dataset in the form of the Spark dataframe 
    
    Args:
    df: a Sparkify dataset
    
    Returns:
    df: a preprocessed Sparkify dataset
    &quot;&quot;&quot;
    # remove user id with empty strings
    df = df.filter(col(&#39;userId&#39;) != &#39;&#39;)
    
    # convert &#39;registration&#39; and &#39;ts&#39; to date format
    df = df \
        .withColumn(&#39;registrationTime&#39;, to_timestamp(col(&#39;registration&#39;)/1000)) \
        .withColumn(&#39;time&#39;, to_timestamp(col(&#39;ts&#39;)/1000)) 
    
    # replace location with extracted state 
    df = df \
        .withColumn(&#39;location&#39;, split(col(&#39;location&#39;),&#39;,&#39;).getItem(1)) \
        .withColumn(&#39;location&#39;, split(col(&#39;location&#39;), &#39;-&#39;).getItem(0))
        
    return df</code></pre>
</div>
</div>
<div id="feature-engineering-and-exploratory-data-analysis" class="section level2">
<h2>Feature engineering and exploratory data analysis</h2>
<p>We use the <em>Cancellation Confirmation</em> events of the <strong>page</strong> column to define the customer churn.</p>
<pre class="python"><code># create a window partitioned by &#39;userId&#39;
userWindow = Window.partitionBy(&#39;userId&#39;).orderBy(&#39;ts&#39;).rangeBetween(Window.unboundedPreceding,Window.unboundedFollowing)

# label churned users to be 1 and unchurned users to be 0 
df = df \
    .withColumn(&#39;Churn&#39;, when(col(&#39;page&#39;)==&#39;Cancellation Confirmation&#39;, 1).otherwise(0)) \
    .withColumn(&#39;Churn&#39;, max(&#39;Churn&#39;).over(userWindow))</code></pre>
<p>By this definition, there are 52 churned users in a total of 225 users in the dataset. That is about 23.1% churn rate. Next, we investigate the following factors of interest for their impact on churn:</p>
<ul>
<li><strong>gender</strong></li>
<li><strong>location</strong>: user’s state</li>
<li><strong>latestLevel</strong>: user’s latest subscription level for each user</li>
<li><strong>registDuration</strong>: user’s registration duration (in days)</li>
<li><strong>avgSessionDuration</strong>: user’s average session duration (in hours)</li>
<li><strong>avgDailySongs</strong>, <strong>avgDailyThumbsUp</strong>, <strong>avgDailyThumbsDown</strong>, <strong>avgDailyUpgrade</strong>, <strong>avgDailyDowngrade</strong>, <strong>avgDailyAddFriend</strong>, <strong>avgDailyAddPlaylist</strong>, <strong>avgDailyAdvert</strong>, <strong>avgDailyHelp</strong>, <strong>avgDailyError</strong>: user’s average daily songs played, thumbs up given, thumbs down given, upgrades, downgrades, friends added, songs added to playlist, advertisements played, help page visits, errors encountered, respectively</li>
</ul>
<p>In this list, only <strong>gender</strong> and <strong>location</strong> are given in the dataset and we need to engineer the rest of them.</p>
<pre class="python"><code># find the latest level of each user
df = df.withColumn(&#39;latestLevel&#39;, last(col(&#39;level&#39;)).over(userWindow))

# calculate the number of days between registration to last activity 
df = df.withColumn(&#39;registDuration&#39;, ((last(col(&#39;ts&#39;)).over(userWindow)-col(&#39;registration&#39;))/1000/3600/24).cast(IntegerType()))

# compute average session duration (in hours)
avg_session_duration_df = df \
    .groupby([&#39;userId&#39;, &#39;sessionId&#39;]).agg(min(col(&#39;ts&#39;)).alias(&#39;session_start&#39;), max(col(&#39;ts&#39;)).alias(&#39;session_end&#39;))\
    .groupby(&#39;userId&#39;).agg(avg((col(&#39;session_end&#39;) - col(&#39;session_start&#39;))/1000/3600).alias(&#39;avgSessionDuration&#39;))

# define the default start and end of the observation period
obs_start_default = df.select(min(col(&#39;ts&#39;))).collect()[0][0]
obs_end_default = df.select(max(col(&#39;ts&#39;))).collect()[0][0]  

# compute the observation period
df = df \
    .withColumn(&#39;obs_start&#39;, when(col(&#39;registration&#39;) &gt; obs_start_default, first(col(&#39;ts&#39;)).over(userWindow)) \
                .otherwise(obs_start_default)) \
    .withColumn(&#39;end_state&#39;, last(col(&#39;page&#39;)).over(userWindow)) \
    .withColumn(&#39;obs_end&#39;, when(col(&#39;end_state&#39;) == &#39;Cancellation Confirmation&#39;, last(col(&#39;ts&#39;)).over(userWindow)) \
                .otherwise(obs_end_default)) \
    .withColumn(&#39;obsDays&#39;, (col(&#39;obs_end&#39;) - col(&#39;obs_start&#39;))/1000/3600/24)

# aggregate activity statistics
user_df = df.groupBy(&#39;userId&#39;) \
            .agg(first(col(&#39;Churn&#39;)).alias(&#39;Churn&#39;), \
                 first(when(col(&#39;gender&#39;) == &#39;M&#39;, 1).otherwise(0)).alias(&#39;gender&#39;), \
                 first(col(&#39;location&#39;)).alias(&#39;location&#39;), \
                 first(when(col(&#39;latestLevel&#39;) == &#39;paid&#39;, 1).otherwise(0)).alias(&#39;latestLevel&#39;), \
                 first(col(&#39;registDuration&#39;)).alias(&#39;registDuration&#39;), \
                 first(col(&#39;obsDays&#39;)).alias(&#39;obsDays&#39;), \
                 sum(when(col(&#39;page&#39;) == &#39;NextSong&#39;, 1).otherwise(0)).alias(&#39;nSongs&#39;), \
                 sum(when(col(&#39;page&#39;) == &#39;Thumbs Up&#39;, 1).otherwise(0)).alias(&#39;nThumbsUp&#39;), \
                 sum(when(col(&#39;page&#39;) == &#39;Thumbs Down&#39;, 1).otherwise(0)).alias(&#39;nThumbsDown&#39;), \
                 sum(when((col(&#39;page&#39;) == &#39;Upgrade&#39;) | (col(&#39;page&#39;) == &#39;Submit Upgrade&#39;), 1).otherwise(0)).alias(&#39;nUpgrade&#39;), \
                 sum(when((col(&#39;page&#39;) == &#39;Downgrade&#39;) | (col(&#39;page&#39;) == &#39;Submit Downgrade&#39;), 1).otherwise(0)).alias(&#39;nDowngrade&#39;), \
                 sum(when(col(&#39;page&#39;) == &#39;Add Friend&#39;, 1).otherwise(0)).alias(&#39;nAddFriend&#39;), \
                 sum(when(col(&#39;page&#39;) == &#39;Add to Playlist&#39;, 1).otherwise(0)).alias(&quot;nAddPlaylist&quot;), \
                 sum(when(col(&#39;page&#39;) == &#39;Roll Advert&#39;, 1).otherwise(0)).alias(&#39;nAdvert&#39;), \
                 sum(when((col(&#39;page&#39;) == &#39;Help&#39;), 1).otherwise(0)).alias(&#39;nHelp&#39;), \
                 sum(when((col(&#39;page&#39;) == &#39;Error&#39;), 1).otherwise(0)).alias(&#39;nError&#39;)) \
            .join(avg_session_duration_df, on=&#39;userId&#39;)

user_df = user_df \
        .withColumn(&#39;avgDailySongs&#39;, col(&#39;nSongs&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyThumbsUp&#39;, col(&#39;nThumbsUp&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyThumbsDown&#39;, col(&#39;nThumbsDown&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyUpgrade&#39;, col(&#39;nUpgrade&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyDowngrade&#39;, col(&#39;nDowngrade&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyAddFriend&#39;, col(&#39;nAddFriend&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyAddPlaylist&#39;, col(&#39;nAddPlaylist&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyAdvert&#39;, col(&#39;nAdvert&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyHelp&#39;, col(&#39;nHelp&#39;) / col(&#39;obsDays&#39;)) \
        .withColumn(&#39;avgDailyError&#39;, col(&#39;nError&#39;) / col(&#39;obsDays&#39;)) \
        .drop(&#39;userId&#39;, &#39;obsDays&#39;, &#39;nSongs&#39;, &#39;nThumbsUp&#39;, &#39;nThumbsDown&#39;, &#39;nUpgrade&#39;, &#39;nDowngrade&#39;, \
              &#39;nAddFriend&#39;, &#39;nAddPlaylist&#39;, &#39;nAdvert&#39;, &#39;nHelp&#39;, &#39;nError&#39;)</code></pre>
<p><img src="gender_latest_level_count.png" style="width:80.0%" /> <img src="location_count.png" style="width:80.0%" /></p>
<p>An overall look at the first three categorical feaures indicates:</p>
<ul>
<li>The churn rates are only slightly higher for male users and free users</li>
<li>The churn rates differ greatly among 41 states. For example, NC has a very low churn rate while there are more churned users than unchurned ones in MI and MS</li>
</ul>
<div class="figure">
<img src="numerical_features_hist.png" style="width:100.0%" />

</div>
<p>By comparing the numerical feature distributions between churned users and unchurned ones, we have the following observations:</p>
<ul>
<li>Churned users have a shorter registration duration on average.</li>
<li>Churned users give more thumbs down, need more help, and have to watch more advertisements per day.</li>
<li>There is no significant difference between churned and unchurned users in terms of average session duration and average daily error.</li>
</ul>
<div id="feature-correlation" class="section level3">
<h3>Feature correlation</h3>
<p>Before we start modeling, we also need to understand the correlation between the response variable and the features as well as the correlation between the features.</p>
<pre class="python"><code>user_df_pd = user_df.toPandas()
# calculate correlations across features (except &#39;location&#39;)
cor_mat = user_df_pd[[&#39;gender&#39;, &#39;latestLevel&#39;,&#39;registDuration&#39;, &#39;avgSessionDuration&#39;,
                     &#39;avgDailySongs&#39;, &#39;avgDailyThumbsUp&#39;, &#39;avgDailyThumbsDown&#39;, &#39;avgDailyUpgrade&#39;, 
                     &#39;avgDailyDowngrade&#39;, &#39;avgDailyAddFriend&#39;,&#39;avgDailyAddPlaylist&#39;,
                     &#39;avgDailyAdvert&#39;, &#39;avgDailyHelp&#39;, &#39;avgDailyError&#39;, &#39;Churn&#39;]].corr()

# plot feature correlations
sns.heatmap(cor_mat, cmap=sns.diverging_palette(240, 20, as_cmap=True), annot=True, square=True, vmin=-1, vmax=1)</code></pre>
<div class="figure">
<img src="feature_correlations.png" style="width:80.0%" />

</div>
<p>From the heatmap above, we find</p>
<ul>
<li><p>There is a high correlation between most of the page event activities. For example, variables <strong>avgDailySongs</strong>, <strong>avgDailyThumbsUp</strong>, <strong>avgDailyDowngrade</strong>, <strong>avgDailyAddFriend</strong>, <strong>avgDailyAddPlaylist</strong> and <strong>avgDailyHelp</strong> are almost perfectly coupled. To avoid multicolinearity in the data, we only retain <strong>avgDailyAddPlaylist</strong> here (as it has the highest correlation with <strong>Churn</strong>).</p></li>
<li><p><strong>Churn</strong> doesn not appear to have strong correlations with any features. <strong>registDuration</strong> is negatively correlated with <strong>Churn</strong> while <strong>avgDaily</strong> has the highest positive correlation with <strong>Churn</strong>. It also shows that <strong>gender</strong>, <strong>latestLevel</strong>, <strong>avgSessionDuration</strong> and <strong>avgDailyError</strong> all have very low correlation with <strong>Churn</strong>. This is consistent with our previous findings through direct visualization. However, the Pearson correlation assumes a linear relationship, and a low correlation simply means that there is no linear relationship between these features and the response variable. The data might still have a nonlinear relationship and should be included in the modeling for now.</p></li>
</ul>
<pre class="python"><code># drop highly correlated features
feat_df = user_df.drop(&#39;avgDailySongs&#39;, &#39;avgDailyThumbsUp&#39;, &#39;avgDailyDowngrade&#39;, &#39;avgDailyAddFriend&#39;, &#39;avgDailyHelp&#39;)</code></pre>
</div>
<div id="feature-transformation" class="section level3">
<h3>Feature transformation</h3>
<p>Spark MLlib requires that the features are formatted as a single vector. Therefore, we create a data pipeline using Spark’s <strong>Pipeline</strong> function to transfrom and vectorize features before we feed them into training. The steps involved in this pipeline include:</p>
<ul>
<li>One hot encode <strong>location</strong> by dummy binary columns</li>
<li>Scale each numberical feature within the range [0,1]</li>
<li>Assemble all features into one vector column</li>
</ul>
<pre class="python"><code>cat_cols=[&#39;gender&#39;, &#39;location&#39;, &#39;latestLevel&#39;]
label=[&#39;Churn&#39;]

# get numerical columns
num_cols = []
for field in feat_df.schema.fields :
    if field.name not in cat_cols + label:
        num_cols.append(field.name)

# convert categorical columns to index columns
indexers = [StringIndexer(inputCol=c, outputCol=&#39;{}_indexed&#39;.format(c)) for c in cat_cols]
    
# one hot encode each categorical column by dummy numerical columns
encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), 
                          outputCol=&#39;{}_encoded&#39;.format(indexer.getOutputCol())) 
            for indexer in indexers]
    
# assemble numerical columns to a single vector column 
num_assembler = VectorAssembler(inputCols=num_cols, outputCol=&#39;num_features&#39;)
    
# scale each numberical feature within the range [0,1] 
scaler = MinMaxScaler(inputCol=&#39;num_features&#39;, outputCol=&#39;scaled_features&#39;)
    
# assemble all vector columns into one vector column
assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + [&#39;scaled_features&#39;], 
                            outputCol=&#39;features&#39;)

# create a pipeline with steps above 
data_pipeline = Pipeline(stages=indexers + encoders + [num_assembler, scaler, assembler])
model_df = data_pipeline.fit(feat_df).transform(feat_df)</code></pre>
<p>Now a vector of 49 features is ready to be used for modeling.</p>
</div>
</div>
<div id="modeling-and-evaluation" class="section level2">
<h2>Modeling and evaluation</h2>
<p>We randomly split the entire dataset into a training and a test set in 8:2 ratio using stratified sampling based on <strong>Churn</strong>.</p>
<pre class="python"><code># split the data into train, validation and test sets using stratified sampling based on &#39;Churn&#39;
train = model_df.sampleBy(&#39;Churn&#39;, fractions={0: 0.8, 1: 0.8}, seed=2020)
test = model_df.subtract(train_val)</code></pre>
<p>Using Spark’s <strong>sampleBy</strong> function, the training, validation and test set now consists of 161, 20 and 44 users, respectively. Notice the training and validation set do not follow a 75/25 split since Spark’s sampleBy function does not guarantee an exact split to the weights (fluctuations often happen if number of records is low). It only guarantees that each object has equal probability to be assigned to a specific subset.</p>
<div id="performance-metrics" class="section level3">
<h3>Performance metrics</h3>
<p>We choose to use the <strong>f1 score</strong> as a performance metric since our dataset is imbalanced. Another metric we look at is the <strong>area under the precision-recall curve (AUC-PR)</strong>. For binary classifier evaluation, precision-recall curves are more useful in practice than the receiver operating characteristic (ROC) curves for problems where the “positive” class is more of interest than the negative class. See: <a href="http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf" class="uri">http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf</a></p>
</div>
<div id="model-selection" class="section level3">
<h3>Model selection</h3>
<p>We select three binary classifiers supported in Spark as candidate models: logistic regression, random forest classifier and gradient-boosted tree classifier. Both random forest and gradient-boosted techniques employ an ensemble of decision trees (base estimators) to improve the predictive capability over a single estimator. The difference is random forest builds several estimators independently and then average their predictions, while gradient-boosted tree buils base estimators sequentially to generate a powerful ensemble. The predictions from the three models on the validation set without tuning are demonstrated below:</p>
<pre class="python"><code>
</code></pre>
<p>The results show that the random forest classifier outperforms both the logistic regression model and the gradient-boosted tree classifier in terms of f1 score and training time. The gradient-boosted tree classifier only performs marginally better than the random forest classifer in AUC-PR. As aforementioned, the features and the response variable do not follow a linear relationship, which suggest that a non-linear model might be more suited to the data.</p>
</div>
<div id="hyperparameter-tuning" class="section level3">
<h3>Hyperparameter tuning</h3>
<p>We decide to tune the random forest model to see if we can improve it further. We performe a grid search with 4-fold cross validation to test the performance of several parameter combinations.</p>
<pre class="python"><code># set hyperparameters for tuning
paramGrid = ParamGridBuilder() \
            .addGrid(rf.numTrees, [20, 40]) \
            .addGrid(rf.maxDepth, [4, 5, 6]) \
            .build()  

# grid search with cross validation    
crossval = CrossValidator(estimator = rf,
                          estimatorParamMaps = paramGrid,
                          evaluator = MulticlassClassificationEvaluator(labelCol=&#39;Churn&#39;, metricName=&#39;f1&#39;),
                          numFolds = 4)

cv_rf = crossval.fit(train_val)
test_prediction = cv_rf.transform(test)

f1_score_evaluator = MulticlassClassificationEvaluator(labelCol=&#39;Churn&#39;, metricName=&#39;f1&#39;)
f1_score = f1_score_evaluator.evaluate(test_prediction.select(&#39;Churn&#39;, &#39;prediction&#39;))

auc_evaluator = BinaryClassificationEvaluator(labelCol=&#39;Churn&#39;)
auc_pr = auc_evaluator.evaluate(test_prediction, {auc_evaluator.metricName:&#39;areaUnderPR&#39;})</code></pre>
<div style="width:100%;">
<table>
<colgroup>
<col width="22%" />
<col width="11%" />
<col width="9%" />
<col width="10%" />
<col width="10%" />
<col width="8%" />
<col width="10%" />
<col width="8%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Classifier</th>
<th align="left">Parameters</th>
<th align="center">Precision</th>
<th></th>
<th align="center">Recall</th>
<th></th>
<th align="center">F1 score</th>
<th></th>
<th align="center">AUC-PR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left"></td>
<td align="center">Overall</td>
<td>Churned</td>
<td align="center">Overall</td>
<td>Churned</td>
<td align="center">Overall</td>
<td>Churned</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">Logistic regression</td>
<td align="left">maxIter=10, regParam=0.1, elasticNetParam=0.5</td>
<td align="center">0.85</td>
<td>1.00</td>
<td align="center">0.82</td>
<td>0.20</td>
<td align="center">0.77</td>
<td>0.33</td>
<td align="center">0.72</td>
</tr>
<tr class="odd">
<td align="left">Random forest classifier</td>
<td align="left">maxDepth=4, numTrees=100</td>
<td align="center">0.86</td>
<td><strong>0.75</strong></td>
<td align="center">0.86</td>
<td><strong>0.60</strong></td>
<td align="center"><strong>0.86</strong></td>
<td>0.67</td>
<td align="center"><strong>0.77</strong></td>
</tr>
<tr class="even">
<td align="left">Gradient-boosted tree classifier</td>
<td align="left">maxDepth=5, maxIter=100</td>
<td align="center">0.77</td>
<td>0.43</td>
<td align="center">0.73</td>
<td>0.60</td>
<td align="center">0.74</td>
<td>0.50</td>
<td align="center">0.65</td>
</tr>
</tbody>
</table>
</div>
<p>The best model is achieved at maxDepth=5 and numTrees=40. We apply this model to the test set, and we obtain a improved <strong>f1 score</strong> of <strong>0.830</strong> and <strong>AUC-PR</strong> of <strong>0.731</strong>.</p>
</div>
<div id="feature-importance" class="section level3">
<h3>Feature importance</h3>
<p>To gain a better understanding of the feature attributes to the model in predicting user churn, we extract feature importances from the trained model.</p>
<pre class="python"><code>features = bin_cols + num_cols
importances = list(cv_rf.bestModel.stages[-1].featureImportances)
feat_imp_pd = pd.DataFrame({&#39;feature&#39;: features, &#39;importance&#39;: importances}).sort_values(&#39;importance&#39;, ascending = False)

# plot feature importance
sns.barplot(data=feat_imp_pd.head(15), y=&quot;feature&quot;, x=&quot;importance&quot;, palette=&#39;Blues_r&#39;, zorder=2)
plt.grid(axis=&#39;x&#39;, linestyle=&#39;--&#39;, zorder=0)
plt.ylabel(&#39;&#39;);</code></pre>
<div class="figure">
<img src="feature_importance.png" style="width:80.0%" />

</div>
<p>It can be seen that the most important feature for identifying churned users is the registration duration which makes sense since it directly reflects a user’s willness to stay with the service. Another influential feature that plays a major role in churn prediction is avarage daily advertisements. Intuitively, the more advertisements a user has to watch, the more likely he/she is dissatisfied with the service. Besides, average upgrades and thumbs down given per day that represent a user’s strong inclination also help churn detection.</p>
<p>The result also shows that gender, latest subscription level and each location feature contribute little to predicting churned users. Nevertheless, we notice that top location features, sch as New England and east south central areas have far different churn rates than the average churn rate.</p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>In this project, we manage to build a random forest classifier that can accurately identify churned users. Since the dataset is relatively clean, the most critical step in the model development process is feature engineering. It has been proved most of the engineered features based on user behaviors play vital roles in churn prediction. For further imporvements, we can test more engineered features that capture the insights about users’ activity patterns and trends. In addtion, a latent issue with our current modeling is that we have 49 features for a dataset with only 225 sample, which may potentially cause the curse of dimensionality. From the analysis of feature importance, we can safely reduce the number of features by discarding most of encoded location featues before feeding them into the model.</p>
</div>
